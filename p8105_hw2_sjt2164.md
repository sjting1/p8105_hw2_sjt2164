Homework 2
================

*Note: This homework uses the `tidyverse`, `dplyr`, and `readxl`
libraries.*

## Problem 1

The `nyctransit_df` dataset (32 columns x 1868 rows) was created based
on the *“NYC_Transit_Subway_Entrance_And_Exit_Data.csv”* file.

After reading the `nyctransit_df` dataset and taking a look at its 32
variables with `summary(nyctransit_df)`, I applied the snake case
convention to the variable names using `clean_names` from the `janitor`
package.

Using the `select()` function, I selected my variables of interest and
converted the `entry` variable in this dataset from character to a
logical variable.

The resulting `nyctransit_q1` dataset (19 columns x 1868 rows) has 19
variables (11 characters, 2 logicals, and 6 doubles).

#### The 19 Variables in `nyctransit_q1`

*Note: To see the categories in some of the character and double
variables, I transformed them into factors and created the
`nyctransit_fc` dataset. Then I used the `levels(pull())` function to
look at the categories.*

In the `nyvtransit_q1` dataset, the 11 character variables include:
`line` (36 different lines), `station_name` (356 different names),
`route1` to `route7`, `entrance_type` (Door, Easement, Elevator,
Escalator, Ramp, Stair, Walkway), and `vending` (y/n).

The 2 logical variables are `ada`, which indicates whether it is ADA
compliant, and `entry`.

The 6 double variables are `station_latitude`, `station_longitude`, and
`route8` to `route11`.

The data in `nyctransit_q1` is not tidy. For example, Routes 8 to 11
were entered as doubles but it is a categorical variable. Similarly,
character variables such as `line`, `entrance_type`, `vending`, and
`route1` to `route7` are categorical variables and could be converted to
factors.

#### Distinct Stations and ADA Compliance

There are 356 distinct stations. 73 out of the 356 stations are ADA
compliant. Of the 36 distinct stations that have entrances/exits without
vending, 16 (44.44%) allow entrance.

After reformatting the data, we find that 56 distinct stations serve the
A train. Of the stations that serve the A train, 16 are ADA compliant.

## Problem 2

Problem 2 uses the *“202409 Trash Wheel Collection Data”* xlsx file from
Mr. Trash Wheel.

#### Summary of Data

3 sheets from the xlsx file (Mr. Trash Wheel, Professor Trash Wheel,
Gwynnda Trash Wheel) have been read, cleaned with the `clean_names`
function, and imported. An additional variable `trash_wheel_name` was
created for all three datasets:

- `mr. trash` (651 x 15)
- `prof_trash` (118 x 14)
- `gwynnda_trash` (262 x 13)

`year` was standardized to a factor variable in all three to allow later
merging of the datasets. Entries in the `sports_ball` variable has been
converted to integers for `mr. trash` only.

After merging, the resulting dataset `Combined_Trash` has 1031
observations and 15 variables. Examples of key variables include:

- `trash_wheel_name` lists the specific names of the trash wheels
- `dumpster` the dumpster number
- Date is specified by the `year`, `month`, and `date` variables
- `weight_tons` and `volume_cubic_yards` of collected trash
- Trash categories include `plastic_bottles`, `polystyrene`,
  `cigarette_butts`, `glass_bottles`, `plastic_bags`, `wrappers`,
  `sports_balls`
- `homes_powered`

The total weight of trash collected by Professor Trash Wheel was 246.74
tons.

In June of 2022, Gwynnda collected a total of 18,120 cigarette butts.

## Problem 3

Problem 3 uses 3 datasets from the Great British Bake Off:
*“bakers.csv”, “bakes.csv”,* and *“results.csv”*.

#### Part 1

##### Summary of Data

The 3 files have been read, cleaned with the `clean_names` function, and
imported as `bakers_df` (120 x 5), `bakes_df` (548 x 5), and
`results_df` (1,136 x 5) datasets. `results_df` was imported by skipping
the first two rows so the dataset makes more sense. After looking at the
variables, I standardized the `series` and `episode` variables to
factors since they are categorical variables. I also separated the
`baker_names` variable into two columns, one of which is named `baker`.
This allows easier merging of the datasets later on.

**Variables**

- `bakers_df` has 3 character variables (`baker_name`,
  `baker_occupation`, `hometown`) 1 factor (`series`), and 1 double
  (`baker_age`).
- `bakes_df` has 3 character variables (`baker`,
  `signature_bake`,`show_stopper`) and 2 factors (`episode`,`series`).
- `results_df` has 2 character variables (`baker`, `results`), 2 factors
  (`series`, `episode`) and 1 double (`technical`)

##### Comparing datasets using `anti_join`

Using the `anti_join` function, I compared the datasets with each other.

- `bakers_bakes` (joined by `baker` and `series`) was created to compare
  data between `bakers_df` and `bakes_df`. It shows that 26 bakers in
  `bakers_df` were absent in `bakes_df`, including Jo Wheatley. However,
  she is actually included in the `bakes_df` with her name in quotation
  marks. Thus, I updated her name in the `bakes_df` without the
  quotations.

- `bakers_results` (joined by `baker`, `series`, and `episodde`) shows
  that Jo was present in `bakers_df` but absent in `results_df`. This is
  because she is entered as “Joanne” for the second dataset. Thus, I
  updated her name to “Jo” in `results_df`.

- After the above updates, no entries were listed in `results_bakers`
  (joined by `baker` and `series`), which compares `results_df` and
  `bakers_df`.

##### Merging

All three datasets have been merged to `combined_data` and columns
rearranged. Entries without values in `results` were deleted and the
file was exported as *“combined_data.csv”* to the data folder of this
repository.The dataset contains information on participants (names, age,
occupation, and hometown), their baking creations (`signature_bake`,
`show_stopper`), `technical` scores, and their `result` at the end of
each episode. There is a total of 10 seasons with 10 episodes each.
`combined_data` has 11 variables and 710 observations.

**Key for `results` in `results_df` dataset**

- IN = stayed in
- OUT = Eliminated
- STAR BAKER = Star Baker
- WINNER = Series Winner
- Runner-up = Series Runner up
- WD = withdrew

#### Part 2

``` r
winner_starbaker = combined_data |>
  select(series:baker_first_name, technical, result) |>
  mutate(result = as.factor(result)) |>
  filter(series > 4 & (result == "STAR BAKER" | result == "WINNER"))

summary(winner_starbaker) #54 star bakers and 6 winners
```

    ##      series        episode     baker_first_name     technical   
    ##  Min.   : 5.0   Min.   : 1.0   Length:60          Min.   :1.00  
    ##  1st Qu.: 6.0   1st Qu.: 3.0   Class :character   1st Qu.:1.00  
    ##  Median : 7.5   Median : 5.5   Mode  :character   Median :2.00  
    ##  Mean   : 7.5   Mean   : 5.5                      Mean   :2.75  
    ##  3rd Qu.: 9.0   3rd Qu.: 8.0                      3rd Qu.:4.00  
    ##  Max.   :10.0   Max.   :10.0                      Max.   :8.00  
    ##                                                                 
    ##         result  
    ##  [a]       : 0  
    ##  IN        : 0  
    ##  OUT       : 0  
    ##  Runner-up : 0  
    ##  STAR BAKER:54  
    ##  WD        : 0  
    ##  WINNER    : 6

``` r
bakers_5_to_10 = distinct(winner_starbaker,baker_first_name) #32 bakers

star_bakers = winner_starbaker |>
  filter(result == "STAR BAKER")

summary(combined_data) #1-13 for technical
```

    ##      series          episode       baker_first_name   baker_last_name   
    ##  Min.   : 1.000   Min.   : 1.000   Length:710         Length:710        
    ##  1st Qu.: 4.000   1st Qu.: 2.000   Class :character   Class :character  
    ##  Median : 6.000   Median : 4.000   Mode  :character   Mode  :character  
    ##  Mean   : 5.845   Mean   : 4.256                                        
    ##  3rd Qu.: 8.000   3rd Qu.: 6.000                                        
    ##  Max.   :10.000   Max.   :10.000                                        
    ##                                                                         
    ##    baker_age     baker_occupation     hometown         signature_bake    
    ##  Min.   :17.00   Length:710         Length:710         Length:710        
    ##  1st Qu.:28.00   Class :character   Class :character   Class :character  
    ##  Median :33.00   Mode  :character   Mode  :character   Mode  :character  
    ##  Mean   :36.92                                                           
    ##  3rd Qu.:45.00                                                           
    ##  Max.   :71.00                                                           
    ##  NA's   :162                                                             
    ##  show_stopper         technical         result         
    ##  Length:710         Min.   : 1.000   Length:710        
    ##  Class :character   1st Qu.: 2.000   Class :character  
    ##  Mode  :character   Median : 4.000   Mode  :character  
    ##                     Mean   : 4.843                     
    ##                     3rd Qu.: 7.000                     
    ##                     Max.   :13.000                     
    ##                     NA's   :14

``` r
summary(star_bakers) #1 - 19 star bakers; range: 1-8
```

    ##      series        episode  baker_first_name     technical            result  
    ##  Min.   : 5.0   Min.   :1   Length:54          Min.   :1.000   [a]       : 0  
    ##  1st Qu.: 6.0   1st Qu.:3   Class :character   1st Qu.:1.000   IN        : 0  
    ##  Median : 7.5   Median :5   Mode  :character   Median :3.000   OUT       : 0  
    ##  Mean   : 7.5   Mean   :5                      Mean   :2.889   Runner-up : 0  
    ##  3rd Qu.: 9.0   3rd Qu.:7                      3rd Qu.:4.000   STAR BAKER:54  
    ##  Max.   :10.0   Max.   :9                      Max.   :8.000   WD        : 0  
    ##                                                                WINNER    : 0

**Table**

There are 54 Star Bakers and 6 Winners out of the 32 bakers who
participated in Series 5 to 10. After looking at the data, I noticed
that the winners in these series had either 1 or 2 for `technical`. The
star bakers had a range of 1 to 8 for `technical` with 19/54 (35.19%)
in 1. The range for the values in `technical` in the `combined_data` is
from 1 to 13. Bakers with a smaller value for `technical` may have a
greater chance of becoming star bakers.

*“viewers.csv”* has been imported, cleaned with `clean_names` function,
and tidied using `mutate()` to change `series` into a double and
`pivot_longer()` to create `series` and `viewer` columns. The resulting
dataset is named `viewers`.

``` r
head(viewers_new, n = 10)
```

    ## # A tibble: 10 × 3
    ##    series episode viewer
    ##     <dbl>   <int>  <dbl>
    ##  1      1       1   2.24
    ##  2      1       2   3   
    ##  3      1       3   3   
    ##  4      1       4   2.6 
    ##  5      1       5   3.03
    ##  6      1       6   2.75
    ##  7      1       7  NA   
    ##  8      1       8  NA   
    ##  9      1       9  NA   
    ## 10      1      10  NA

What was the average viewership in Season 1 is 2.77. In Season 5, it was
10.039.
